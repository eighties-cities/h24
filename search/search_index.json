{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Here you can find</p> <ul> <li> <p>workflow for H24 library</p> </li> <li> <p>documentation explaining main steps. Still in progress (cf.     here)</p> </li> </ul>"},{"location":"#team","title":"Team","text":"<p>Cl\u00e9mentine Cottineau-Mugadza, Julien Perret, Romain Reuillon, S\u00e9bastien Rey-Coyrehourcq, Julie Vall\u00e9e</p>"},{"location":"#related-paper","title":"Related paper","text":"<p>An agent-based model to investigate the effects of urban segregation around the clock on inequalities in health behaviour (submitted)</p>"},{"location":"#about-website","title":"About website","text":"<ul> <li> <p>Pour modifier les options et la navigation du site, tout est dans le     <code>../mkdocs.yml</code></p> </li> <li> <p>Pour \u00e9crire du code source \"inline\", par exemple, en python :     <code>range()</code> est la m\u00e9thode qui sert \u00e0 g\u00e9n\u00e9rer des s\u00e9quences.</p> </li> <li> <p>Pour \u00e9crire des bouts de code, voir dans workflow.md pour la     fonction <code>code_from_file(...)</code></p> </li> <li> <p>Pour les infobox, les icones/emoji, etc. voir la     documentation</p> </li> </ul> <p>Le site est fait avec MkDocs, et l'extension material.</p> <p>Il est compil\u00e9 via une github action, voir dans le folder <code>.github/workflows/mail.yml</code></p> <p>La documentation est une primo-\u00e9tape souvent oubli\u00e9 vers la reproductibilit\u00e9. La todo list pour une vrai reproductibilit\u00e9 qui permettrait ensuite de s'autonomiser vis \u00e0 vis des outils actuels dev instable (python, scala, github api, mkdocs api, etc. ) est ensuite longue...</p> <p>En attendant la sortie de Dottydoc, qui permettra d'extraire facilement des signatures <code>.scala</code> pour les convertir au format markdown, le site utilise une b\u00eate macro en python, avec sed et l'injecter dans le code.</p> <p>La macro (<code>/docs/macro.py</code>) en question s'appuie sur un plugin mkdocs macro.</p> <p>Les plugins pour mkdocs utilis\u00e9 la doc de mkdocs sont list\u00e9s dans le .yml : inlinehilite, highlight, emoji</p>"},{"location":"doc/","title":"Documentation about H24 library","text":""},{"location":"doc/#step-1-generating-population","title":"Step 1 Generating population","text":"<p>Initial distribution of population (<code>population.bin</code>) is generated using the <code>PopulationGenerator</code> tools Object with correct input parameters/data :</p> <pre><code>    rnd: Random,\n    irises: Seq[AreaID],\n    geometry: AreaID =&gt; Option[MultiPolygon],\n    age10: Map[AreaID, Vector[Double]],\n    ageSex: Map[AreaID, Vector[Double]],\n    schoolAge: Map[AreaID, Vector[Double]],\n    educationSex: Map[AreaID, Vector[Vector[Double]]],\n    cells: STRtree): Seq[Seq[IndividualFeature]] = {\n    val env = cells.getRoot.getBounds\n</code></pre> <p>Parameters of <code>eighties.h24.tools.PopulationGenerator</code></p> <ul> <li><code>c</code> shape of Iris,</li> <li><code>p</code> &amp; <code>f</code> population structure and education from census,</li> <li><code>g</code> population density in raster format,</li> <li><code>s</code> grid size for population projection</li> <li><code>r</code> if you want a random population</li> </ul> <p>Given population density we build a matrix of cells.</p> <p>Next, the function <code>generation.generatePopulationRandomly</code> (generation.scala) use information about structure of population (age, sex, education) at the census block level (iris) to sample new population sized individuals using direct sampling algorithm.</p> <pre><code>  case class IndividualFeature(\n    ageCategory: Int,\n    sex: Int,\n    education: Int,\n    location: space.Location)\n</code></pre> <p>We don't consider the census block geometries, so we attribute for each individual (<code>IndividualFeature</code>) a random cell in a matrix of same size of the population raster grid. This random cell is taken using a multinomial to respect density of population.</p> <p>Finally, individuals (x,y) are translated/relocated to some new grid of cells function of the <code>gridSize</code> parameter.</p>"},{"location":"doc/#step-2-move-population","title":"Step 2 Move population","text":""},{"location":"doc/#understanding-the-big-picture","title":"Understanding the \"Big Picture\"","text":""},{"location":"doc/#building-aggregatedcategories","title":"Building AggregatedCategories","text":"<p>We take a simple example extracted from a very simple EGT with only four people and a 4*4 grid of places.</p> <p></p> <p>We start by building our aggregated categories using h24 <code>social.scala</code> package, using fine category described by EGT : </p> <ul> <li>John is a male of 24 years, with education coded as SUP</li> <li>Paul is a male of 39 years, with education coded as SUP</li> </ul> <p>In h24 John and Paul are grouped in the same <code>aggregatedCategory</code> : {gender male ;30-59 years ;up education}  </p> <p>If we look the grid we see the different places and activities that John, Paul practice for one day. We read this graphic like that : </p> <ul> <li>John stay at home (1,1) between 0h and 9h, then go to workplace (2,2) between 9h and 19h, and go back to home (1,1) at 19h. </li> <li>Paul stay at home (2,2) between 0h and 6h, then go to workplace (3,0) between 6h and 15h, practice an activity (1,0) between 15h and 23h, then go back to home (2,2) at 23h.</li> </ul> <p>Now, if we look at (b) :</p> <ul> <li>Anna is a female of 22 years, with education coded as BAC</li> <li>Lily is a female of 26 years, with education coded as BACP2</li> </ul> <p>We apply the same algorithm for Anna and Lily that are grouped in the same <code>aggregatedCategory</code> : {gender female ;15-29 years ;middle education}</p> <p>We read the Timeslice and the Matrix of places and activities like (a).</p>"},{"location":"doc/#building-moves-for-aggregatedcategory","title":"Building moves for AggregatedCategory","text":"<p>In this next step algorithm build move for each AggregatedCategory. To do that, we cumulate the time spent by each individual by cutting it into three time slice.</p> <p>If we look at (a) : </p> <ul> <li>In the first [0h - 8h] time slice : </li> <li>John stay at home during 8h in (1,1);</li> <li>Paul stay at home during 6h in (0,3) and go to work during 2h in (2,2)</li> </ul> <p>=&gt; for this time slice we aggregate these numbers in a list of [((place),hour);...] : [((2,2),8); ((0,3),6); ((2,2),2)]</p> <ul> <li>In the second [8h - 16h] time slice :</li> <li>John stay at home during 1h in (1,1) then go to work 7h in (2,2)</li> <li>Paul stay at work during 7h in (2,2) then go to activity 1h in (0,1)</li> </ul> <p>=&gt; for this time slice we aggregate these numbers in a list of [((place),hour);...] : [((0,1),1); ((1,1),1); ((2,2),14)]</p> <ul> <li>In the third [16h - 24h] time slice :</li> <li>John stay at work during 3h in (2,2) then go to home 5h in (1,1)</li> <li>Paul stay at activy during 7h in (0,1) then go to home 1h in (0,3)</li> </ul> <p>=&gt; for this time slice we aggregate these numbers in a list of [((place),hour);...] : [((0,1),7); ((0,3),1); ((1,1),5), ((2,2),3)]</p> <p>These three list encode the <code>Moves</code> made by people of <code>AggregatedCategory {gender male ;30-59 years ;up education}</code> to <code>Cells</code> for each <code>Time Slice</code>. </p> <p>We use the same algorithm for the other <code>AggregatedCategory</code> in (b)</p>"},{"location":"doc/#interpolate","title":"Interpolate","text":"<p>ECG contain only a small parts of the real population. We use a simple IDW (Inverse Distance Weighting) interpolation to compute values for all cells that contain actually no moves.</p> <p></p> <p>If we consider starting from centroid of each cell : foul\u00e9e.</p> <ul> <li>distance of 1 for horizontal and vertical move </li> <li>distance of 1.41 for diagonal move</li> </ul> <p>In we compute the interpolated value for cell (1,1), with power 2, the computation with precision of 2 is :</p> <p>((5/(1.41^2)) + (7/(1^2)) + (4/(1.41^2))) / ((1/(1.41^2)) + (1/(1^2)) + (1/(1.41^2))) ~= 5.76</p> <p>You could also see in this figure the generalisation of the computation with a precision of 2.</p>"},{"location":"doc/#understanding-source-code-in-detail","title":"Understanding source code in detail","text":"<p>Using EGT and population previously generated, flows are precomputed as File (<code>move.bin</code>) before running simulation.</p> <p>In <code>generation.scala</code> , in <code>flowsFromEgt(...)</code> the method <code>readFlowsFromEGT()</code> return an <code>Array[Flow]</code></p> <p>We build a <code>MoveMatrix</code> (in reality a <code>Vector[TimeSlice, CellsMatrix]</code>) where <code>CellsMatrix</code> is an <code>Array[Array[Cell]]</code>  :</p> <ul> <li>A <code>Move</code> is an object with an index and a ratio.</li> <li>A <code>Cell</code> is a Map which associate an <code>AggregatedCategory</code> with an array of <code>Move</code></li> <li>An <code>AggregatedCategory</code> object take a category (ex.<code>Education.SUP</code>) as input and return the coresponding aggregated category (ex. <code>HIGH</code>)</li> <li>A TimeSlice is a vector of TimeSlices (0-8,8-16,16-24) :<ul> <li>(0-8) - Empty Map for each Cell in Matrix</li> <li>(8-16) - Empty Map for each Cell in Matrix</li> <li>(16-24) - Empty Map for each Cell in Matrix</li> </ul> </li> </ul> <p>We first build a vector of <code>MoveMatrix</code> with empty array of Move for AggregatedCategory.</p> <p>For each <code>TimeSlice</code> by reading flows from EGT file (<code>Array[Flow]</code>) and aggregate them by Cell (<code>addFlowToCell</code> function).</p> <pre><code>  for each nm in `Vector[TimeSlice, CellsMatrix]`  \n   for each flow f in EGT  \n     a) we get the Cell c at (x,y) of residence of current flow \n     b) we update these Cell c by calling addFlowToCell() function\n</code></pre> <p>The <code>addFlowToCell()</code> function add the contribution of a flow to <code>Cell</code> for a given timeslice by : - computing the length of intersection between first <code>mn</code> timeslice and <code>f</code> timeslice. - attributing an aggregated category <code>cat</code> to this flow. - calculating :     - if intersection is 0, cell <code>c</code> is not updated     - else we create or update the <code>Array[Move]</code> for this <code>cat</code> .     - If a <code>Move</code> already exist for the activity location of this flow, we update this Move by adding our contribution.</p> <pre><code>  def addFlowToCell(c: Cell, flow: Flow, timeSlice: TimeSlice): Cell = {\n    val intersection = overlap(flow.timeSlice, timeSlice).toDouble\n    val cat = AggregatedSocialCategory(SocialCategory(age = flow.age, sex = flow.sex, education = flow.education))\n\n    if(intersection &lt;= 0.0) c\n    else\n      c.get(cat) match {\n        case Some(moves) =&gt;\n          val index = moves.indexWhere { m =&gt; Move.location.get(m) == flow.activity }\n          if (index == -1) c + (cat -&gt; moves.:+ (Move(flow.activity, intersection.toFloat)))\n          else {\n            val v = MoveMatrix.Move.ratio.get(moves(index))\n            c + (cat -&gt; moves.updated(index, Move(flow.activity, v + intersection.toFloat)))\n          }\n        case None =&gt;\n          c + (cat -&gt; Array(Move(flow.activity, intersection.toFloat)))\n      }\n  }\n</code></pre> <p>After that, MoveMatrix is interpolated (<code>interpolate(...)</code>) then normalized (<code>normalizedFlows(...)</code>).</p> <p>Because EGT flows are a small parts of real flow, we scale MoveMatrix CellsMatrix build using EGT at IDF level by interpolating values to neighbors. Each CellsMatrix could be interpreted as a probability by category at individual level.</p> <p>To normalize CellsMatrix, we use <code>getMovesFromOppositeSex(...)</code>: in order to get more samples in areas where we have little information, we also use the information from samples in the area with the same categories but different sex</p>"},{"location":"doc/#step-2-simulating","title":"Step 2 Simulating","text":"<ul> <li>Chargement de <code>results/population.bin</code>   (ageCategory, sexe, education ) dans un vecteur d' <code>IndividualFeature</code></li> <li>fct <code>generateWorld</code> :<ul> <li><code>IndividualFeature</code> sont rewrapp\u00e9s dans des case class Age, Sexe, Education, Comportement, Lieu dans <code>Individual</code></li> <li>On filtre cette population en fonction du pr\u00e9dicat de la fonction <code>included</code></li> <li>Genere le monde <code>World</code> en fonction du vecteur <code>Individual</code>, fonction comportement de type <code>Behaviour</code> (double) et une graine  al\u00e9atoire. </li> </ul> </li> </ul>"},{"location":"workflows/","title":"Requirement","text":"<ul> <li>You need to install sbt from https://www.scala-sbt.org/download/</li> <li>You need to GDAL for the preprocessing steps from https://gdal.org/en/stable/download.html</li> </ul>"},{"location":"workflows/#workflow-to-generate-synthetic-population-with-h24-library","title":"Workflow to generate synthetic population with H24 library","text":""},{"location":"workflows/#install","title":"Install","text":"<pre><code>sbt publishLocal\n</code></pre>"},{"location":"workflows/#generate-a-synthetic-population-for-your-study-area","title":"Generate a synthetic population for your study area","text":""},{"location":"workflows/#get-files-for-your-study-area","title":"Get Files for your study area","text":"<p>Run the getData.sh script.</p> <pre><code>source getData.sh\n</code></pre> <p>It will:</p> <ul> <li>download the CONTOURS-IRIS files from http://professionnel.ign.fr/contoursiris for instance: https://data.geopf.fr/telechargement/download/CONTOURS-IRIS/CONTOURS-IRIS_2-0__SHP_LAMB93_FXX_2014-01-01/CONTOURS-IRIS_2-0__SHP_LAMB93_FXX_2014-01-01.7z</li> <li>download R_rfl09_LAEA1000 file from https://www.insee.fr/fr/statistiques/fichier/1405815/ECP1KM_09_MET.zip</li> <li>download base-ic-evol-struct-pop file from https://www.insee.fr/fr/statistiques/fichier/2028582/infra-population-2012.zip</li> <li>download base-ic-diplomes-formation file from https://www.insee.fr/fr/statistiques/fichier/2028265/infra-formation-2012.zip</li> </ul> <p>You should now have a \"data\" directory with all the relevant data in it. Note: We should have these files on IPFS very soon.</p>"},{"location":"workflows/#select-the-relevant-data-for-your-study-area","title":"Select the relevant data for your study area","text":"<ul> <li>geographically for CONTOURS-IRIS and R_rfl09_LAEA1000</li> <li>by selection using DEP, COM or other relevant codes for base-ic-evol-struct-pop and base-ic-diplomes-formation (keep headers and everything, just filter the data)</li> <li>export the latter files as CSV and create csv.lzma files</li> </ul> <p>This whole process can be automatically done using the following command:</p> <pre><code>sbt \"runMain eighties.h24.tools.ExtractRelevantData -c data/CONTOURS-IRIS_2-0__SHP_LAMB93_FXX_2014-01-01/CONTOURS-IRIS/1_DONNEES_LIVRAISON_2014/CONTOURS-IRIS_2-0_SHP_LAMB93_FE-2014/CONTOURS-IRIS_FE.shp -g data/GRID/R_rfl09_LAEA1000.shp -p data/base-ic-evol-struct-pop-2012.xls -f data/base-ic-diplomes-formation-2012.xls -d dep_list -o prepared_data\"\n</code></pre> <p>Where dep_list is a list of \"d\u00e9partements\" you wish to extract from your data and prepared_data is the output directory.</p> <p>For instance, the following command extracts the data for the 44 d\u00e9partement (Loire Atlantique):</p> <pre><code>sbt \"runMain eighties.h24.tools.ExtractRelevantData -c data/CONTOURS-IRIS_2-0__SHP_LAMB93_FXX_2014-01-01/CONTOURS-IRIS/1_DONNEES_LIVRAISON_2014/CONTOURS-IRIS_2-0_SHP_LAMB93_FE-2014/CONTOURS-IRIS_FE.shp -g data/GRID/R_rfl09_LAEA1000.shp -p data/base-ic-evol-struct-pop-2012.xls -f data/base-ic-diplomes-formation-2012.xls -d 44 -o prepared_data_44\"\n</code></pre> <p>The following command extracts the data for the entire \u00cele-de-France r\u00e9gion:</p> <pre><code>sbt \"runMain eighties.h24.tools.ExtractRelevantData -c data/CONTOURS-IRIS_2-0__SHP_LAMB93_FXX_2014-01-01/CONTOURS-IRIS/1_DONNEES_LIVRAISON_2014/CONTOURS-IRIS_2-0_SHP_LAMB93_FE-2014/CONTOURS-IRIS_FE.shp -g data/GRID/R_rfl09_LAEA1000.shp -p data/base-ic-evol-struct-pop-2012.xls -f data/base-ic-diplomes-formation-2012.xls -d 75,77,78,91,92,93,94,95 -o prepared_data_IDF\"\n</code></pre> <p>The following command extracts the data for Metropolitan France:</p> <pre><code>sbt \"runMain eighties.h24.tools.ExtractRelevantData -c data/CONTOURS-IRIS_2-0__SHP_LAMB93_FXX_2014-01-01/CONTOURS-IRIS/1_DONNEES_LIVRAISON_2014/CONTOURS-IRIS_2-0_SHP_LAMB93_FE-2014/CONTOURS-IRIS_FE.shp -g data/GRID/R_rfl09_LAEA1000.shp -p data/base-ic-evol-struct-pop-2012.xls -f data/base-ic-diplomes-formation-2012.xls -o prepared_data\"\n</code></pre> <p>You get the idea, right?</p>"},{"location":"workflows/#you-are-ready-to-generate-you-synthetic-population","title":"You are ready to generate you synthetic population!","text":"<p>Let's keep our examples running. The parameters should look familiar.</p> <p>For Loire-Atlantique:</p> <pre><code>sbt \"runMain eighties.h24.tools.PopulationGenerator -c prepared_data_44/CONTOURS-IRIS_FE.shp -g prepared_data_44/R_rfl09_LAEA1000.shp -s 1000 -p prepared_data_44/base-ic-evol-struct-pop-2012.csv.lzma -f prepared_data_44/base-ic-diplomes-formation-2012.csv.lzma -o results_44/population.bin\"\n</code></pre> <p>For \u00cele-de-France (note we added a JVM option to give more memory to the process):</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.PopulationGenerator -c prepared_data_IDF/CONTOURS-IRIS_FE.shp -g prepared_data_IDF/R_rfl09_LAEA1000.shp -s 1000 -p prepared_data_IDF/base-ic-evol-struct-pop-2012.csv.lzma -f prepared_data_IDF/base-ic-diplomes-formation-2012.csv.lzma -o results_IDF/population.bin\"\n</code></pre> <p>For Metropolitan France:</p> <pre><code>sbt -J-Xmx8G \"runMain eighties.h24.tools.PopulationGenerator -c prepared_data/CONTOURS-IRIS_FE.shp -g prepared_data/R_rfl09_LAEA1000.shp -s 1000 -p prepared_data/base-ic-evol-struct-pop-2012.csv.lzma -f prepared_data/base-ic-diplomes-formation-2012.csv.lzma -o results/population.bin\"\n</code></pre>"},{"location":"workflows/#export-you-synthetic-population","title":"Export you synthetic population!","text":"<p>You can also export the population as a shapefile to see how it looks like.</p> <p>For \u00cele-de-France (note we added a JVM option to give more memory to the process):</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.PopulationShapefileExporter -p results_IDF/population.bin -o results_IDF/population.shp\"\n</code></pre> <p>For Metropolitan France, a shapefile will not work, you can use the geopackage exporter:</p> <pre><code>sbt -J-Xmx8G \"runMain eighties.h24.tools.PopulationGeopackageExporter -p results/population.bin -o results/population.gpkg\"\n</code></pre> <p>And now, you have a Metropolitan France synthetic population! </p>"},{"location":"workflows/#generate-and-export-a-synthetic-population-in-buildings","title":"Generate and export a synthetic population in buildings","text":"<p>If you want to create a synthetic population in buildings, you can do so.</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.PopulationInBuildingsGenerator -o results/populationInBuildings.gpkg -c prepared_data/CONTOURS-IRIS_FE.shp -b prepared_data/buildings.shp -p prepared_data/base-ic-evol-struct-pop-2012.csv.lzma -f prepared_data/base-ic-diplomes-formation-2012.csv.lzma\"\n</code></pre> <p>To illustrate the results, here is a map of a population generated for Paris.  The heatmap of the same population with a radius of 500 meters.  The heatmap of the same area using the population grid from INSEE (with a radius of 500 meters) . </p>"},{"location":"workflows/#generate-a-move-matrix-from-data-coming-from-origin-destination-survey","title":"Generate a move matrix from data coming from origin-destination survey","text":"<p>For more data about origin-destination survey and methods for pre-processing, please see <code>preprocessing_odsurvey/readme.md</code> </p> <p>For \u00cele-de-France (note we added a JVM option to give more memory to the process):</p> <pre><code>unzip InputODData/H24_location_noID_ParisRegion.zip -d prepared_data_IDF/\nlzma -f prepared_data_IDF/H24_location_noID_ParisRegion.csv\nsbt -J-Xmx4G \"runMain eighties.h24.tools.MoveMatrixGenerator -e prepared_data_IDF/H24_location_noID_ParisRegion.csv.lzma -s EPSG:27572 -p results_IDF/population.bin -m results_IDF/moves.bin\"\n</code></pre> <p>For Loire-Atlantique (note we added a JVM option to give more memory to the process):</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.MoveMatrixGenerator -e prepared_data_44/H24_location_noID_NantesRegion.csv.lzma -s EPSG:2154 -p results_44/population.bin -m results_44/moves.bin\"\n</code></pre> <p>Please also note that we need to specify the SRID used in the input survey.</p>"},{"location":"workflows/#optionally-check-your-matrix","title":"Optionally, check your matrix","text":"<p>Generate the matrix destinations</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.EGTShapefileExporter -p results_IDF/population.bin -m results_IDF/moves.bin -d true -o results_IDF/destinations.shp\"\n</code></pre> <p>Generate the matrix origins</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.EGTShapefileExporter -p results_IDF/population.bin -m results_IDF/moves.bin -d false -o results_IDF/origins.shp\"\n</code></pre> <p>To see what the matrix looks like, you can generate a CSV file containing (parts of) the OD flows:</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.EGTShapefileExporter -p results_IDF/population.bin -m results_IDF/moves.bin -o flowmap/flows.csv\"\n</code></pre> <p>You can now see it if you open the index.html in you browser. You can also filter the flows using a timeslice, sex, age, education &amp; a percentile:</p> <pre><code>sbt -J-Xmx4G \"runMain eighties.h24.tools.EGTCSVExporter -p results_IDF/population.bin -m results_IDF/moves.bin -t 0 -a 1 -s 1 -e 1 -o flowmap/flows_0_1_1_1_0.5.csv\"\n</code></pre>"},{"location":"workflows/#run-an-empty-simulation","title":"Run an \"empty\" Simulation","text":"<p>You can now run a simple 'empty' simulation with the test app.</p> <p>For \u00cele-de-France:</p> <pre><code>sbt -J-Xmx2G \"runMain eighties.h24.tools.SimulationApp -p results_IDF/population.bin -m results_IDF/moves.bin -d 1 -o maps_IDF\"\n</code></pre> <p>For Loire-Atlantique:</p> <pre><code>sbt -J-Xmx2G \"runMain eighties.h24.tools.SimulationApp -p results_44/population.bin -m results_44/moves.bin -d 1 -o maps_44\"\n</code></pre>"}]}